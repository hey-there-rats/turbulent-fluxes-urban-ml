{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b319a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06d0b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ДИАГНОСТИКА ===\n",
      "1. Текущая папка: c:\\Users\\User\\OneDrive\\Документы\\GitHub\\turbulent-fluxes-urban-ml\n",
      "2. Файл существует: True\n",
      "3. Python exe: c:\\Users\\User\\anaconda3\\envs\\python312\\python.exe\n",
      "\n",
      "4. Проверка netCDF4:\n",
      "   ✅ netCDF4 видит файл\n",
      "\n",
      "5. Проверка xarray:\n",
      "   ✅ xarray видит файл\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "\n",
    "print(\"=== ДИАГНОСТИКА ===\")\n",
    "print(\"1. Текущая папка:\", os.getcwd())\n",
    "print(\"2. Файл существует:\", os.path.exists('US-Baltimore_clean_observations_v1.nc'))\n",
    "print(\"3. Python exe:\", sys.executable)\n",
    "\n",
    "# Проверяем оба способа\n",
    "print(\"\\n4. Проверка netCDF4:\")\n",
    "try:\n",
    "    ds_nc = nc.Dataset('US-Baltimore_clean_observations_v1.nc', 'r')\n",
    "    print(\"   ✅ netCDF4 видит файл\")\n",
    "    ds_nc.close()\n",
    "except Exception as e:\n",
    "    print(\"   ❌ netCDF4:\", e)\n",
    "\n",
    "print(\"\\n5. Проверка xarray:\")\n",
    "try:\n",
    "    ds_xr = xr.open_dataset(r\"C:\\US-Baltimore_clean_observations_v1.nc\", engine='netcdf4')\n",
    "    print(\"   ✅ xarray видит файл\")\n",
    "except Exception as e:\n",
    "    print(\"   ❌ xarray:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c712e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': \"<class 'netCDF4.Dimension'>\": name = 'time', size = 43824}\n",
      "['time', 'SWdown', 'LWdown', 'Tair', 'Qair', 'PSurf', 'Rainf', 'Snowf', 'Wind_N', 'Wind_E', 'SWup', 'LWup', 'Qle', 'Qh', 'SoilTemp', 'Qtau', 'SWdown_qc', 'LWdown_qc', 'Tair_qc', 'Qair_qc', 'PSurf_qc', 'Rainf_qc', 'Snowf_qc', 'Wind_N_qc', 'Wind_E_qc', 'SWup_qc', 'LWup_qc', 'Qle_qc', 'Qh_qc', 'SoilTemp_qc', 'Qtau_qc']\n"
     ]
    }
   ],
   "source": [
    "dataset = nc.Dataset('US-Baltimore_clean_observations_v1.nc', 'r')\n",
    "print (dataset.dimensions)\n",
    "print (list(dataset.variables.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34699420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4MB\n",
      "Dimensions:      (time: 43824)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 351kB 2002-01-01T05:00:00 ... 2007-01-...\n",
      "Data variables: (12/30)\n",
      "    SWdown       (time) float32 175kB ...\n",
      "    LWdown       (time) float32 175kB ...\n",
      "    Tair         (time) float32 175kB ...\n",
      "    Qair         (time) float32 175kB ...\n",
      "    PSurf        (time) float32 175kB ...\n",
      "    Rainf        (time) float32 175kB ...\n",
      "    ...           ...\n",
      "    SWup_qc      (time) int8 44kB ...\n",
      "    LWup_qc      (time) int8 44kB ...\n",
      "    Qle_qc       (time) int8 44kB ...\n",
      "    Qh_qc        (time) int8 44kB ...\n",
      "    SoilTemp_qc  (time) int8 44kB ...\n",
      "    Qtau_qc      (time) int8 44kB ...\n",
      "Attributes: (12/24)\n",
      "    title:                      Flux tower observations from US-Baltimore (af...\n",
      "    summary:                    Quality controlled flux tower observations fo...\n",
      "    sitename:                   US-Baltimore\n",
      "    long_sitename:              Cub Hill, Baltimore, United States\n",
      "    version:                    v1\n",
      "    keywords:                   urban, flux tower, eddy covariance, observations\n",
      "    ...                         ...\n",
      "    observations_contact:       Ben Crawford (benjamin.crawford@ucdenver.edu)...\n",
      "    observations_reference:     Crawford, Grimmond and Christen (2011): https...\n",
      "    date_created:               2022-09-22 16:41:55\n",
      "    source:                     https://github.com/matlipson/urban-plumber_pi...\n",
      "    comment:                    Hourly rainfall from Baltimore Washington Int...\n",
      "    history:                    v0.9 (2021-09-08): beta issue; v1 (2022-09-15...\n"
     ]
    }
   ],
   "source": [
    "dataset = xr.open_dataset(r\"C:\\US-Baltimore_clean_observations_v1.nc\", engine='netcdf4') #только для чтения\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15d73496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qh: 14336/43824 пропусков(32.71%)\n",
      "Qle: 24166/43824 пропусков(55.14%)\n",
      "Qtau: 7615/43824 пропусков(17.38%)\n",
      "Tair: 248/43824 пропусков(0.57%)\n",
      "Wind_N: 7472/43824 пропусков(17.05%)\n",
      "Wind_E: 7472/43824 пропусков(17.05%)\n"
     ]
    }
   ],
   "source": [
    "for var_name in ['Qh', 'Qle', 'Qtau', 'Tair', 'Wind_N', 'Wind_E']: #используемые предикторы\n",
    "    if var_name in dataset.data_vars:\n",
    "        data = dataset[var_name]\n",
    "        missing_count = np.isnan(data).sum().item()\n",
    "        missing_pct = (missing_count / data.size)*100\n",
    "        print (f\"{var_name}: {missing_count}/{data.size} пропусков({missing_pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "259a4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qh:\n",
      "  Линейная интерполяция: заполнено 14331\n",
      "  Осталось после линейной: 5\n",
      "  Сезонное заполнение: заполнено 5\n",
      "  Осталось после сезонного: 0\n",
      "итог: заполнено 14336 из 14336 пропусков\n",
      "пропуски устранены\n",
      "Qle:\n",
      "  Линейная интерполяция: заполнено 23915\n",
      "  Осталось после линейной: 251\n",
      "  Сезонное заполнение: заполнено 29\n",
      "  Осталось после сезонного: 222\n",
      "  Агрессивное заполнение: заполнено 222\n",
      "  Осталось после агрессивного: 0\n",
      "итог: заполнено 24166 из 24166 пропусков\n",
      "пропуски устранены\n",
      "Qtau:\n",
      "  Линейная интерполяция: заполнено 7610\n",
      "  Осталось после линейной: 5\n",
      "  Сезонное заполнение: заполнено 5\n",
      "  Осталось после сезонного: 0\n",
      "итог: заполнено 7615 из 7615 пропусков\n",
      "пропуски устранены\n",
      "Tair:\n",
      "  Линейная интерполяция: заполнено 248\n",
      "  Осталось после линейной: 0\n",
      "итог: заполнено 248 из 248 пропусков\n",
      "пропуски устранены\n",
      "Wind_N:\n",
      "  Линейная интерполяция: заполнено 7467\n",
      "  Осталось после линейной: 5\n",
      "  Сезонное заполнение: заполнено 5\n",
      "  Осталось после сезонного: 0\n",
      "итог: заполнено 7472 из 7472 пропусков\n",
      "пропуски устранены\n",
      "Wind_E:\n",
      "  Линейная интерполяция: заполнено 7467\n",
      "  Осталось после линейной: 5\n",
      "  Сезонное заполнение: заполнено 5\n",
      "  Осталось после сезонного: 0\n",
      "итог: заполнено 7472 из 7472 пропусков\n",
      "пропуски устранены\n"
     ]
    }
   ],
   "source": [
    "for var_name in ['Qh', 'Qle', 'Qtau', 'Tair', 'Wind_N', 'Wind_E']:\n",
    "    data = dataset[var_name]\n",
    "    missing_count = np.isnan(data).sum().item()\n",
    "    data_interpolated = data.interpolate_na(dim='time', method='linear') #линейная интерполяция\n",
    "    missing_after_linear = np.isnan(data_interpolated).sum().item()\n",
    "    filled_count = missing_count - missing_after_linear\n",
    "    print(f\"{var_name}:\")\n",
    "    print(f\"  Линейная интерполяция: заполнено {filled_count}\")\n",
    "    print(f\"  Осталось после линейной: {missing_after_linear}\")\n",
    "\n",
    "    missing_after_seasonal = missing_after_linear\n",
    "\n",
    "    if missing_after_linear > 0:\n",
    "        data_interpolated = data_interpolated.ffill(dim='time', limit=24) #интерполяция вперед на сутки\n",
    "        data_interpolated = data_interpolated.bfill(dim='time', limit=24) #назад\n",
    "        missing_after_seasonal = np.isnan(data_interpolated).sum().item()\n",
    "        filled_seasonal = missing_after_linear - missing_after_seasonal\n",
    "        print(f\"  Сезонное заполнение: заполнено {filled_seasonal}\")\n",
    "        print(f\"  Осталось после сезонного: {missing_after_seasonal}\")\n",
    "\n",
    "    if missing_after_seasonal > 0:\n",
    "        data_interpolated = data_interpolated.ffill(dim='time') #агрессивная интерполяция\n",
    "        data_interpolated = data_interpolated.bfill(dim='time')\n",
    "        missing_after_aggressive = np.isnan(data_interpolated).sum().item()\n",
    "        filled_aggressive = missing_after_seasonal - missing_after_aggressive\n",
    "        print(f\"  Агрессивное заполнение: заполнено {filled_aggressive}\")\n",
    "        print(f\"  Осталось после агрессивного: {missing_after_aggressive}\")\n",
    "    \n",
    "    dataset[var_name] = data_interpolated\n",
    "    \n",
    "    final_missing = np.isnan(dataset[var_name]).sum().item() #файнал результат\n",
    "    total_filled = missing_count - final_missing\n",
    "    print(f\"итог: заполнено {total_filled} из {missing_count} пропусков\")\n",
    "    \n",
    "    if final_missing == 0:\n",
    "        print(\"пропуски устранены\")\n",
    "    else:\n",
    "        print(f\"осталось пропусков: {final_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6271ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e991323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_physical_limits(data, var_name):\n",
    "    limits = {\n",
    "        'Qh': (-500, 1000),\n",
    "        'Qle': (-100, 1500),\n",
    "        'Qtau': (0, 5)\n",
    "    }\n",
    "    if var_name in limits:\n",
    "        min_val, max_val = limits[var_name]\n",
    "\n",
    "        cleaned = np.where ((data >= min_val) & (data <= max_val), data, np.nan)\n",
    "        return cleaned\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
